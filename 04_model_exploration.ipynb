{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# from src.flair_ner import flair_batch_predict, save_as_flair_fmt, load_flair_corpus, train_flair_ner, load_flair_ner\n",
    "\n",
    "with open(\"data/train.json\") as f:\n",
    "    train = json.load(f)\n",
    "\n",
    "with open(\"data/test.json\") as f:\n",
    "    test = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random model\n",
    "\n",
    "It's always a good idea to start with a non-sense model to make sure evaluation is working and set a baseline.\n",
    "\n",
    "If our approaches have similar results to the non-sense model, then something might be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'token': ['Tempo', 'Prod', 'Writes'], 'labels': [(0, 1, 'ENV')]},\n",
       " {'token': ['Cortex', 'us-prod', 'full', 'outage'],\n",
       "  'labels': [(0, 1, 'ENV'), (1, 2, 'SVC')]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from src.utils import extract_spans, evaluate_ner\n",
    "\n",
    "labels_to_predict = ['O', 'B-SVC', 'B-ENV']\n",
    "\n",
    "random.seed(42)\n",
    "random_predictions = [\n",
    "    {\n",
    "        \"token\": data['tokens'],\n",
    "        \"labels\": extract_spans([random.choice(labels_to_predict) for _ in range(len(data['tokens']))])\n",
    "    }\n",
    "    for data in test\n",
    "]\n",
    "\n",
    "random_predictions[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.1250    0.2500    0.1667         8\n",
      "         SVC     0.2500    0.2000    0.2222        10\n",
      "\n",
      "   micro avg     0.1667    0.2222    0.1905        18\n",
      "   macro avg     0.1875    0.2250    0.1944        18\n",
      "weighted avg     0.1944    0.2222    0.1975        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_score = evaluate_ner(test, random_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex model\n",
    "\n",
    "Simple model like regex or using heuristic can work surprisingly well sometimes. Especially in cases where we don't have sufficient data.\n",
    "\n",
    "In this example, we don't actually need a training data since we should be able to just generate a list of services and environments we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Alerting',\n",
       "  'Alertmanager',\n",
       "  'Billing',\n",
       "  'Cloud Alerting',\n",
       "  'CloudNAT',\n",
       "  'CloudSQL',\n",
       "  'Codecov',\n",
       "  'Cortex',\n",
       "  'CortexTank',\n",
       "  'Drone',\n",
       "  'Enterprise',\n",
       "  'GEM',\n",
       "  'Grafana',\n",
       "  'Grafanacom',\n",
       "  'Grafanas',\n",
       "  'Graphite',\n",
       "  'HG',\n",
       "  'HG CloudSQL',\n",
       "  'Hosted Grafana',\n",
       "  'Ingester',\n",
       "  'Logs',\n",
       "  'Loki',\n",
       "  'ML',\n",
       "  'Machine Learning',\n",
       "  'Metamonitoring',\n",
       "  'Metrictank',\n",
       "  'Mimir',\n",
       "  'OnCall',\n",
       "  'Prometheus',\n",
       "  'Remote Write',\n",
       "  'Ruler',\n",
       "  'SM',\n",
       "  'SMTP Proxy',\n",
       "  'Stack Driver NAT',\n",
       "  'Stack State',\n",
       "  'Stacks',\n",
       "  'Synthetic Monitoring',\n",
       "  'Tempo',\n",
       "  'WorldPing',\n",
       "  'billing',\n",
       "  'cortex',\n",
       "  'cortex-blocks',\n",
       "  'grafana com',\n",
       "  'grafana-com',\n",
       "  'ingester',\n",
       "  'loki',\n",
       "  'ruler',\n",
       "  'synthetic-monitoring'},\n",
       " {'Azure',\n",
       "  'EU',\n",
       "  'Prod',\n",
       "  'Production',\n",
       "  'billing',\n",
       "  'cortex-dedicated-08',\n",
       "  'cortex-prod-04',\n",
       "  'cortex-prod-10',\n",
       "  'free cluster',\n",
       "  'loki-prod',\n",
       "  'loki-prod-3',\n",
       "  'ops',\n",
       "  'prod',\n",
       "  'prod-eu-west-0',\n",
       "  'prod-eu-west-0/loki-prod',\n",
       "  'prod-us-central',\n",
       "  'prod-us-central-0',\n",
       "  'us-central1'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.regex_ner import RegexModel\n",
    "\n",
    "# get list of services and environments\n",
    "services = set()\n",
    "environments = set()\n",
    "\n",
    "for data in train:\n",
    "    for span in data['labels']:\n",
    "        span_text = \" \".join(data['tokens'][span[0]:span[1]]) \n",
    "        if span[2] == 'SVC':\n",
    "            services.add(span_text)\n",
    "        elif span[2] == 'ENV':\n",
    "            environments.add(span_text)\n",
    "\n",
    "services, environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo\n",
      "['Tempo'] 0 0 Tempo Prod Writes\n",
      "Prod\n",
      "['Prod'] 1 1 Tempo Prod Writes\n",
      "Cortex\n",
      "['Cortex'] 0 0 Cortex us-prod full outage\n",
      "prod\n",
      "['prod'] 2 2 Cortex us-prod full outage\n",
      "loki\n",
      "['loki'] 0 0 loki-prod3 write outage\n",
      "Alertmanager\n",
      "['Alertmanager'] 0 0 Alertmanager UI not working\n",
      "loki\n",
      "['loki'] 0 0 loki ops ingester panics\n",
      "ingester\n",
      "['ingester'] 2 2 loki ops ingester panics\n",
      "ops\n",
      "['ops'] 1 1 loki ops ingester panics\n",
      "us-central1\n",
      "['us-central1'] 0 0 us-central1 prod checkpoint failed\n",
      "prod\n",
      "['prod'] 1 1 us-central1 prod checkpoint failed\n",
      "Billing\n",
      "['Billing'] 0 0 Billing Prometheus Down\n",
      "Prometheus\n",
      "['Prometheus'] 1 1 Billing Prometheus Down\n",
      "Billing\n",
      "['Billing'] 0 0 Billing Prometheus Down\n",
      "cortex\n",
      "['cortex'] 0 0 cortex-dedicated-04 write path\n",
      "SM\n",
      "['SM'] 0 0 SM Vultr Probe Outage\n",
      "Cortex\n",
      "['Cortex'] 0 0 Cortex Billing Ruler Issues\n",
      "Billing\n",
      "['Billing'] 1 1 Cortex Billing Ruler Issues\n",
      "Ruler\n",
      "['Ruler'] 2 2 Cortex Billing Ruler Issues\n",
      "Billing\n",
      "['Billing'] 1 1 Cortex Billing Ruler Issues\n",
      "Alertmanager\n",
      "['Alertmanager'] 0 0 Alertmanager can read any file\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.5714    0.5000    0.5333         8\n",
      "         SVC     0.8333    1.0000    0.9091        10\n",
      "\n",
      "   micro avg     0.7368    0.7778    0.7568        18\n",
      "   macro avg     0.7024    0.7500    0.7212        18\n",
      "weighted avg     0.7169    0.7778    0.7421        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regex_model = RegexModel()\n",
    "regex_model.fit(services, environments)\n",
    "\n",
    "regex_bio = regex_model.predict(test)\n",
    "\n",
    "regex_predictions = [\n",
    "    {\n",
    "        \"token\": data['tokens'],\n",
    "        \"labels\": extract_spans([l[1] for l in label])\n",
    "    }\n",
    "    for data, label in zip(test, regex_bio)\n",
    "]\n",
    "\n",
    "regex_score = evaluate_ner(test, regex_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning model\n",
    "\n",
    "This is a transformers based model that is similar to the technologies behind LLMs/Generative AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-03 21:50:33,182 Reading data from data\n",
      "2024-06-03 21:50:33,183 Train: data/train.txt\n",
      "2024-06-03 21:50:33,184 Dev: None\n",
      "2024-06-03 21:50:33,184 Test: data/test.txt\n",
      "2024-06-03 21:50:33,188 No dev split found. Using 0% (i.e. 10 samples) of the train split as dev data\n"
     ]
    }
   ],
   "source": [
    "from src.flair_ner import flair_batch_predict, save_as_flair_fmt, load_flair_corpus, load_flair_ner, train_flair_ner\n",
    "\n",
    "# save the data in flair format\n",
    "save_as_flair_fmt(train, \"data/train.txt\")\n",
    "save_as_flair_fmt(test, \"data/test.txt\")\n",
    "\n",
    "corpus = load_flair_corpus(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"models/flair-ner\"\n",
    "\n",
    "# Train the model\n",
    "# train_flair_ner(corpus, save_path, max_epochs=200, base_model=\"prajjwal1/bert-mini\")\n",
    "\n",
    "# get pre-trained model from Google Cloud Storage\n",
    "# !wget https://storage.googleapis.com/edwardqian-dev/workshop/best-model.pt -o f\"{save_path}/best-model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-03 21:50:33,611 SequenceTagger predicts: Dictionary with 9 tags: O, S-SVC, B-SVC, E-SVC, I-SVC, S-ENV, B-ENV, E-ENV, I-ENV\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.5000    0.2500    0.3333         8\n",
      "         SVC     0.6000    0.9000    0.7200        10\n",
      "\n",
      "   micro avg     0.5789    0.6111    0.5946        18\n",
      "   macro avg     0.5500    0.5750    0.5267        18\n",
      "weighted avg     0.5556    0.6111    0.5481        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flair_model = load_flair_ner(f\"{save_path}/best-model.pt\")\n",
    "\n",
    "from flair.data import Sentence\n",
    "\n",
    "test_sentences = [Sentence(\" \".join(d[\"tokens\"])) for d in test]\n",
    "flair_pred = flair_batch_predict(flair_model, test_sentences,  batch_size = 1)\n",
    "\n",
    "flair_score = evaluate_ner(test, flair_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative AI Model\n",
    "\n",
    "What if we use generative AI to solve this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.gpt_ner import gpt_ner\n",
    "# gpt_bio = gpt_ner(str([\" \".join(d[\"tokens\"]) for d in test]), model=\"gpt-4-turbo\")\n",
    "\n",
    "\n",
    "gpt_bio = [['B-SVC', 'I-SVC', 'O', 'O', 'O', 'B-ENV'],\n",
    " ['B-SVC', 'I-SVC', 'B-ENV', 'I-ENV', 'I-ENV', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'I-SVC', 'O', 'I-ENV', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'O', 'O', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'I-SVC', 'O', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'I-SVC', 'I-SVC', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'O', 'O', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'I-SVC', 'I-SVC', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'I-SVC', 'O', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'I-SVC', 'O', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'I-SVC', 'I-SVC', 'I-SVC', 'O']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.0000    0.0000    0.0000       8.0\n",
      "         SVC     0.0000    0.0000    0.0000      10.0\n",
      "\n",
      "   micro avg     0.0000    0.0000    0.0000      18.0\n",
      "   macro avg     0.0000    0.0000    0.0000      18.0\n",
      "weighted avg     0.0000    0.0000    0.0000      18.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_predictions = [\n",
    "    {\n",
    "        \"token\": data['tokens'],\n",
    "        \"labels\": extract_spans(label)\n",
    "    }\n",
    "    for data, label in zip(test, gpt_bio)\n",
    "]\n",
    "gpt_predictions\n",
    "\n",
    "gpt_score = evaluate_ner(test, gpt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.1250    0.2500    0.1667         8\n",
      "         SVC     0.2500    0.2000    0.2222        10\n",
      "\n",
      "   micro avg     0.1667    0.2222    0.1905        18\n",
      "   macro avg     0.1875    0.2250    0.1944        18\n",
      "weighted avg     0.1944    0.2222    0.1975        18\n",
      "\n",
      "Regex Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.5714    0.5000    0.5333         8\n",
      "         SVC     0.8333    1.0000    0.9091        10\n",
      "\n",
      "   micro avg     0.7368    0.7778    0.7568        18\n",
      "   macro avg     0.7024    0.7500    0.7212        18\n",
      "weighted avg     0.7169    0.7778    0.7421        18\n",
      "\n",
      "Flair Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.5000    0.2500    0.3333         8\n",
      "         SVC     0.6000    0.9000    0.7200        10\n",
      "\n",
      "   micro avg     0.5789    0.6111    0.5946        18\n",
      "   macro avg     0.5500    0.5750    0.5267        18\n",
      "weighted avg     0.5556    0.6111    0.5481        18\n",
      "\n",
      "GPT Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.0000    0.0000    0.0000       8.0\n",
      "         SVC     0.0000    0.0000    0.0000      10.0\n",
      "\n",
      "   micro avg     0.0000    0.0000    0.0000      18.0\n",
      "   macro avg     0.0000    0.0000    0.0000      18.0\n",
      "weighted avg     0.0000    0.0000    0.0000      18.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at all the results\n",
    "\n",
    "print(\"Random Model\")\n",
    "print(random_score)\n",
    "\n",
    "print(\"Regex Model\")\n",
    "print(regex_score)\n",
    "\n",
    "print(\"Flair Model\")\n",
    "print(flair_score)\n",
    "\n",
    "print(\"GPT Model\")\n",
    "print(gpt_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the incorrect predictions\n",
    "\n",
    "Looking at scores are great, but they don't tell the whole story.\n",
    "\n",
    "It is ALWAYS a good idea to look at the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regex_model\n",
      "Text: Cortex us-prod full outage\n",
      "True: ['Cortex (SVC)', 'us-prod (ENV)']\n",
      "Pred: ['Cortex (SVC)', 'full (ENV)']\n",
      "\n",
      "Text: loki-prod3 write outage\n",
      "True: ['loki-prod3 (ENV)']\n",
      "Pred: ['loki-prod3 (SVC)']\n",
      "\n",
      "Text: us-central1 prod checkpoint failed\n",
      "True: ['us-central1 prod (ENV)']\n",
      "Pred: ['us-central1 (ENV)', 'prod (ENV)']\n",
      "\n",
      "Text: cortex-dedicated-04 write path\n",
      "True: ['cortex-dedicated-04 (ENV)']\n",
      "Pred: ['cortex-dedicated-04 (SVC)']\n",
      "\n",
      "flair_model\n",
      "Text: loki-prod3 write outage\n",
      "True: ['loki-prod3 (ENV)']\n",
      "Pred: ['loki-prod3 (SVC)']\n",
      "\n",
      "Text: loki ops ingester panics\n",
      "True: ['loki (SVC)', 'ops (ENV)', 'ingester (SVC)']\n",
      "Pred: ['loki (SVC)', 'ops (SVC)']\n",
      "\n",
      "Text: us-central1 prod checkpoint failed\n",
      "True: ['us-central1 prod (ENV)']\n",
      "Pred: ['us-central1 (ENV)', 'prod (ENV)']\n",
      "\n",
      "Text: Billing Prometheus Down\n",
      "True: ['Billing (ENV)', 'Prometheus (SVC)']\n",
      "Pred: ['Billing (SVC)', 'Prometheus (SVC)']\n",
      "\n",
      "Text: cortex-dedicated-04 write path\n",
      "True: ['cortex-dedicated-04 (ENV)']\n",
      "Pred: ['cortex-dedicated-04 (SVC)']\n",
      "\n",
      "gpt_model\n",
      "Text: Tempo Prod Writes\n",
      "True: ['Tempo (SVC)', 'Prod (ENV)']\n",
      "Pred: ['Tempo Prod (SVC)', ' (ENV)']\n",
      "\n",
      "Text: Cortex us-prod full outage\n",
      "True: ['Cortex (SVC)', 'us-prod (ENV)']\n",
      "Pred: ['Cortex us-prod (SVC)', 'full outage (ENV)']\n",
      "\n",
      "Text: loki-prod3 write outage\n",
      "True: ['loki-prod3 (ENV)']\n",
      "Pred: ['loki-prod3 write outage (SVC)']\n",
      "\n",
      "Text: Alertmanager UI not working\n",
      "True: ['Alertmanager (SVC)']\n",
      "Pred: ['Alertmanager UI (SVC)']\n",
      "\n",
      "Text: loki ops ingester panics\n",
      "True: ['loki (SVC)', 'ops (ENV)', 'ingester (SVC)']\n",
      "Pred: ['loki ops ingester (SVC)']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at some sample incorrect predictions\n",
    "\n",
    "def print_sample_errors(true, pred, n=5):\n",
    "    for i, (t, p) in enumerate(zip(true, pred)):\n",
    "        t_spans = []\n",
    "        p_spans = []\n",
    "\n",
    "        for tl in t[\"labels\"]:\n",
    "            t_spans.append(f\"{' '.join(t['tokens'][tl[0]:tl[1]])} ({tl[2]})\")\n",
    "        for pl in p[\"labels\"]:\n",
    "            p_spans.append(f\"{' '.join(t['tokens'][pl[0]:pl[1]])} ({pl[2]})\")\n",
    "\n",
    "        if sorted(t_spans) != sorted(p_spans):\n",
    "            print(f\"Text: {' '.join(t['tokens'])}\")\n",
    "            print(f\"True: {t_spans}\")\n",
    "            print(f\"Pred: {p_spans}\")\n",
    "            print()\n",
    "            n -= 1\n",
    "        if n == 0:\n",
    "            break\n",
    "\n",
    "print(\"regex_model\")\n",
    "print_sample_errors(test, regex_predictions)\n",
    "print(\"flair_model\")\n",
    "print_sample_errors(test, flair_pred)\n",
    "print(\"gpt_model\")\n",
    "print_sample_errors(test, gpt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of distribution data\n",
    "\n",
    "Our previous test data is randomly split from the training data.\n",
    "\n",
    "This data is good for development, but is not a true measure of data that the model has not seen before.\n",
    "\n",
    "Let's see what happens if we evalute our model on a completely different type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_dist_labels = [\n",
    "    {\"tokens\": [\"Kube\", \"API\", \"Server\", \"Down\", \"in\", \"preprod\"],\n",
    "     \"labels\": [(0, 2, \"SVC\"), (5, 6, \"ENV\")]},\n",
    "    {\"tokens\": [\"Metrics\", \"Server\", \"Scaling\", \"Issues\", \"for\", \"test-na-4\"],\n",
    "     \"labels\": [(0, 2, \"SVC\"), (5, 6, \"ENV\")]},\n",
    "    {\"tokens\": [\"Redshift\", \"me-south-3\", \"Data\", \"Corruption\"],\n",
    "     \"labels\": [(0, 1, \"SVC\"), (1, 2, \"ENV\")]},\n",
    "    {\"tokens\": [\"Elasticsearch\", \"Cluster\", \"Overload\"],\n",
    "     \"labels\": [(0, 1, \"SVC\")]},\n",
    "    {\"tokens\": [\"Kafka\", \"Stream\", \"Delays\", \"in\", \"sandbox\", \"env\"],\n",
    "     \"labels\": [(0, 1, \"SVC\"), (4, 5, \"ENV\")]},\n",
    "    {\"tokens\": [\"Redis\", \"Cache\", \"Failure\", \"in\", \"prod-2,\", \"dev,\", \"and\", \"staging\"],\n",
    "     \"labels\": [(0, 2, \"SVC\"), (4, 5, \"ENV\"), (5, 6, \"ENV\"), (7, 8, \"ENV\")]},\n",
    "    {\"tokens\": [\"MongoDB\", \"Backup\", \"Failures\"], \"labels\": [(0, 1, \"SVC\")]},\n",
    "    {\"tokens\": [\"Nginx\", \"Proxy\", \"Timeout\"], \"labels\": [(0, 2, \"SVC\")]},\n",
    "    {\"tokens\": [\"Docker\", \"Registry\", \"Unreachable\"], \"labels\": [(0, 2, \"SVC\")]},\n",
    "    {\"tokens\": [\"GitLab\", \"CI\", \"Pipeline\", \"Stuck\"], \"labels\": [(0, 2, \"SVC\")]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod\n",
      "['prod'] 4 4 Redis Cache Failure in prod-2, dev, and staging\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         SVC     0.0000    0.0000    0.0000        10\n",
      "         ENV     1.0000    0.1429    0.2500         7\n",
      "\n",
      "   micro avg     1.0000    0.0588    0.1111        17\n",
      "   macro avg     0.5000    0.0714    0.1250        17\n",
      "weighted avg     0.4118    0.0588    0.1029        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Regex model\n",
    "regex_ood_bio = regex_model.predict(out_of_dist_labels)\n",
    "regex_ood_predictions = [\n",
    "    {\n",
    "        \"token\": data['tokens'],\n",
    "        \"labels\": extract_spans([l[1] for l in label])\n",
    "    }\n",
    "    for data, label in zip(out_of_dist_labels, regex_ood_bio)\n",
    "]\n",
    "ood_regex_score = evaluate_ner(out_of_dist_labels, regex_ood_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     1.0000    0.1429    0.2500         7\n",
      "         SVC     0.2857    0.2000    0.2353        10\n",
      "\n",
      "   micro avg     0.3750    0.1765    0.2400        17\n",
      "   macro avg     0.6429    0.1714    0.2426        17\n",
      "weighted avg     0.5798    0.1765    0.2413        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "ood_flair_labels = [Sentence(\" \".join(d['tokens'])) for d in out_of_dist_labels]\n",
    "ood_flair_pred = flair_batch_predict(flair_model, ood_flair_labels, batch_size=4)\n",
    "ood_flair_score = evaluate_ner(out_of_dist_labels, ood_flair_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ENV     0.7500    0.8571    0.8000         7\n",
      "         SVC     0.6000    0.6000    0.6000        10\n",
      "\n",
      "   micro avg     0.6667    0.7059    0.6857        17\n",
      "   macro avg     0.6750    0.7286    0.7000        17\n",
      "weighted avg     0.6618    0.7059    0.6824        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from src.gpt_ner import gpt_ner\n",
    "# ood_gpt_bio = gpt_ner(str([\" \".join(d[\"tokens\"]) for d in out_of_dist_labels]), model=\"gpt-4-turbo\")\n",
    "ood_gpt_bio = [['B-SVC', 'I-SVC', 'I-SVC', 'O', 'O', 'B-ENV'],\n",
    " ['B-SVC', 'I-SVC', 'O', 'O', 'O', 'B-ENV'],\n",
    " ['B-SVC', 'B-ENV', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'O', 'O', 'B-ENV', 'I-ENV'],\n",
    " ['B-SVC', 'I-SVC', 'O', 'O', 'B-ENV', 'B-ENV', 'B-ENV', 'B-ENV'],\n",
    " ['B-SVC', 'O', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'O'],\n",
    " ['B-SVC', 'I-SVC', 'I-SVC', 'O']]\n",
    "\n",
    "ood_gpt_predictions = [\n",
    "    {\n",
    "        \"token\": data['tokens'],\n",
    "        \"labels\": extract_spans(label)\n",
    "    }\n",
    "    for data, label in zip(out_of_dist_labels, ood_gpt_bio)\n",
    "]\n",
    "ood_gpt_score = evaluate_ner(out_of_dist_labels, ood_gpt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regex_model\n",
      "Text: Kube API Server Down in preprod\n",
      "True: ['Kube API (SVC)', 'preprod (ENV)']\n",
      "Pred: []\n",
      "\n",
      "Text: Metrics Server Scaling Issues for test-na-4\n",
      "True: ['Metrics Server (SVC)', 'test-na-4 (ENV)']\n",
      "Pred: []\n",
      "\n",
      "Text: Redshift me-south-3 Data Corruption\n",
      "True: ['Redshift (SVC)', 'me-south-3 (ENV)']\n",
      "Pred: []\n",
      "\n",
      "Text: Elasticsearch Cluster Overload\n",
      "True: ['Elasticsearch (SVC)']\n",
      "Pred: []\n",
      "\n",
      "Text: Kafka Stream Delays in sandbox env\n",
      "True: ['Kafka (SVC)', 'sandbox (ENV)']\n",
      "Pred: []\n",
      "\n",
      "flair_model\n",
      "Text: Kube API Server Down in preprod\n",
      "True: ['Kube API (SVC)', 'preprod (ENV)']\n",
      "Pred: ['Kube (SVC)']\n",
      "\n",
      "Text: Metrics Server Scaling Issues for test-na-4\n",
      "True: ['Metrics Server (SVC)', 'test-na-4 (ENV)']\n",
      "Pred: ['Metrics (SVC)']\n",
      "\n",
      "Text: Redshift me-south-3 Data Corruption\n",
      "True: ['Redshift (SVC)', 'me-south-3 (ENV)']\n",
      "Pred: []\n",
      "\n",
      "Text: Kafka Stream Delays in sandbox env\n",
      "True: ['Kafka (SVC)', 'sandbox (ENV)']\n",
      "Pred: ['Kafka (SVC)']\n",
      "\n",
      "Text: Redis Cache Failure in prod-2, dev, and staging\n",
      "True: ['Redis Cache (SVC)', 'prod-2, (ENV)', 'dev, (ENV)', 'staging (ENV)']\n",
      "Pred: ['prod-2, (ENV)']\n",
      "\n",
      "gpt4\n",
      "Text: Kube API Server Down in preprod\n",
      "True: ['Kube API (SVC)', 'preprod (ENV)']\n",
      "Pred: ['Kube API Server (SVC)', 'preprod (ENV)']\n",
      "\n",
      "Text: Elasticsearch Cluster Overload\n",
      "True: ['Elasticsearch (SVC)']\n",
      "Pred: ['Elasticsearch Cluster (SVC)']\n",
      "\n",
      "Text: Kafka Stream Delays in sandbox env\n",
      "True: ['Kafka (SVC)', 'sandbox (ENV)']\n",
      "Pred: ['Kafka Stream (SVC)', 'sandbox env (ENV)']\n",
      "\n",
      "Text: Redis Cache Failure in prod-2, dev, and staging\n",
      "True: ['Redis Cache (SVC)', 'prod-2, (ENV)', 'dev, (ENV)', 'staging (ENV)']\n",
      "Pred: ['Redis Cache (SVC)', 'prod-2, (ENV)', 'dev, (ENV)', 'and (ENV)', 'staging (ENV)']\n",
      "\n",
      "Text: GitLab CI Pipeline Stuck\n",
      "True: ['GitLab CI (SVC)']\n",
      "Pred: ['GitLab CI Pipeline (SVC)']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at some sample incorrect predictions\n",
    "\n",
    "print(\"regex_model\")\n",
    "print_sample_errors(out_of_dist_labels, regex_ood_predictions)\n",
    "print(\"flair_model\")\n",
    "print_sample_errors(out_of_dist_labels, ood_flair_pred)\n",
    "print(\"gpt4\")\n",
    "print_sample_errors(out_of_dist_labels, ood_gpt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
